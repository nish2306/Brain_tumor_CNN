# -*- coding: utf-8 -*-
"""Brain_Tumor_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EG8-KnsGqZhZnPooM0sp7binPcuMVXAt
"""

!pip install keras.tuner

!apt-get install tree
#clear_output()
# create new folders
!mkdir TRAIN TEST VAL TRAIN/YES TRAIN/NO TEST/YES TEST/NO VAL/YES VAL/NO
!tree -d

import tensorflow as tf
from tensorflow import keras
import numpy as np

#print(tf.__version__)

import cv2
import pickle
import os
import shutil

#os.removedirs('/content/VAL')

IMG_PATH = '/content/drive/MyDrive/CNN_project_on_Brain_tumor/brain_tumor_dataset'
# split the data by train/val/test
for sub_folder in os.listdir(IMG_PATH):
  if not sub_folder.startswith('.'):
    IMG_NUM = len(os.listdir(IMG_PATH + '/' + sub_folder))
    for (n, FILE_NAME) in enumerate(os.listdir(IMG_PATH + '/' + sub_folder)):
      img = IMG_PATH + '/' + sub_folder + '/' + FILE_NAME
      if n < 5:
        shutil.copy(img, '/content/TEST/'+ sub_folder.upper()  + '/')
      elif n < 0.8*IMG_NUM:
        shutil.copy(img, '/content/TRAIN/'+sub_folder.upper()+"/")
      else:
        shutil.copy(img, '/content/VAL/'+sub_folder.upper()+'/')

def load_data(dir_path):
    """
    Load images as np.arrays
    """
    X = []
    y = []
    i = 0
    labels = dict()
    for path in tqdm(sorted(os.listdir(dir_path))):
        if not path.startswith('.'):
            labels[i] = path
            for file in os.listdir(dir_path + path):
                if not file.startswith('.'):
                    img = cv2.imread(dir_path + path + '/' + file)
                    X.append(img)
                    y.append(i)
            i += 1
    X = np.array(X)
    y = np.array(y)
    print(f'{len(X)} images loaded from {dir_path} directory.')
    return X, y, labels

from tqdm import tqdm

TRAIN_DIR = '/content/TRAIN/'
TEST_DIR = '/content/TEST/'
VAL_DIR = '/content/VAL/'
IMG_SIZE = (224,224)  #as for vgg16 we need 224*224 size images

# use predefined function to load the image data into workspace
X_train, y_train, labels = load_data(TRAIN_DIR)
X_test, y_test, _ = load_data(TEST_DIR)
X_val, y_val, _ = load_data(VAL_DIR)

import matplotlib.pyplot as plt

"""Function: To view some images in their actual size"""

def View_images(X, y, labels_dict, n=50):
    """
    Creates a gridplot for desired number of images (n) from the specified set
    """
    for index in range(len(labels_dict)):
        imgs = X[np.argwhere(y == index)][:n]
        j = 10
        i = int(n/j)

        plt.figure(figsize=(15,6))
        c = 1
        for img in imgs:
            plt.subplot(i,j,c)
            plt.imshow(img[0])

            plt.xticks([])
            plt.yticks([])
            c += 1
        plt.suptitle('Tumor: {}'.format(labels_dict[index]))
        plt.show()

View_images(X_train, y_train, labels, 10)

import imutils

def crop_imgs(set_name, add_pixels_value=0):
    """
    Finds the extreme points on the image and crops the rectangular out of them
    """
    set_crop = []
    for img in set_name:
        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        gray = cv2.GaussianBlur(gray, (5, 5), 0)

        # thresholding the image
        thresh_img = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]
        
        # erosions on image
        erode_img = cv2.erode(thresh_img, None, iterations=2)
        # dilations on image
        dil_img = cv2.dilate(erode_img, None, iterations=2)

        # find contours in processed image
        border = cv2.findContours(dil_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        # selecting largest one
        sel_border = imutils.grab_contours(border)
        c = max(sel_border, key=cv2.contourArea)

        # find the extreme points
        extLeft = tuple(c[c[:, :, 0].argmin()][0])
        extRight = tuple(c[c[:, :, 0].argmax()][0])
        extTop = tuple(c[c[:, :, 1].argmin()][0])
        extBot = tuple(c[c[:, :, 1].argmax()][0])

        ADD_PIXELS = add_pixels_value
        crop_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()
        set_crop.append(crop_img)

    return np.array(set_crop)

#Example of above crop function

img = cv2.imread('/content/drive/MyDrive/CNN_project_on_Brain_tumor/brain_tumor_dataset/yes/Y1.jpg')
img = cv2.resize(
            img,
            dsize=IMG_SIZE,
            interpolation=cv2.INTER_CUBIC
        )
gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
gray_blur = cv2.GaussianBlur(gray, (5, 5), 0)
thresh_img = cv2.threshold(gray_blur, 45, 255, cv2.THRESH_BINARY)[1]
erode_img = cv2.erode(thresh_img, None, iterations=2)
dil_img = cv2.dilate(erode_img, None, iterations=2)

border = cv2.findContours(dil_img.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
sel_border = imutils.grab_contours(border)
c = max(sel_border, key=cv2.contourArea)

# find the extreme points
extLeft = tuple(c[c[:, :, 0].argmin()][0])
extRight = tuple(c[c[:, :, 0].argmax()][0])
extTop = tuple(c[c[:, :, 1].argmin()][0])
extBot = tuple(c[c[:, :, 1].argmax()][0])

# add contour on the image
img_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)

# add extreme points
img_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)
img_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)
img_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)
img_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)

# crop
ADD_PIXELS = 0
crop_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()

plt.figure(figsize=(15,6))
plt.subplot(141)
plt.imshow(img)
plt.xticks([])
plt.yticks([])
plt.title('Original image')
plt.subplot(142)
plt.imshow(img_cnt)
plt.xticks([])
plt.yticks([])
plt.title('Biggest contour')
plt.subplot(143)
plt.imshow(img_pnt)
plt.xticks([])
plt.yticks([])
plt.title('Extreme points')
plt.subplot(144)
plt.imshow(crop_img)
plt.xticks([])
plt.yticks([])
plt.title('Cropped image')
plt.show()

# apply this function on each set
X_train_crop = crop_imgs(set_name=X_train)
X_val_crop = crop_imgs(set_name=X_val)
X_test_crop = crop_imgs(set_name=X_test)

View_images(X_train_crop, y_train, labels, 10)

"""Function: To save cropped images"""

def save_crop_images(x_set, y_set, folder_name):
    i = 0
    for (img, imclass) in zip(x_set, y_set):
        if imclass == 0:
            cv2.imwrite(folder_name+'NO/'+str(i)+'.jpg', img)
        else:
            cv2.imwrite(folder_name+'YES/'+str(i)+'.jpg', img)
        i += 1

# Creating folder to save cropped images
!mkdir TRAIN_CROP TEST_CROP VAL_CROP TRAIN_CROP/YES TRAIN_CROP/NO TEST_CROP/YES TEST_CROP/NO VAL_CROP/YES VAL_CROP/NO

# saving new images to the folder
save_crop_images(X_train_crop, y_train, folder_name='/content/TRAIN_CROP/')
save_crop_images(X_val_crop, y_val, folder_name='/content/VAL_CROP/')
save_crop_images(X_test_crop, y_test, folder_name='/content/TEST_CROP/')

"""Data Augumentation"""

from keras.preprocessing.image import ImageDataGenerator
from keras.applications.vgg16 import VGG16, preprocess_input

from keras import layers
from keras.models import Model, Sequential
from keras.optimizers import Adam, RMSprop

from plotly.offline import init_notebook_mode, iplot
init_notebook_mode(connected=True)
RANDOM_SEED = 123

"""Creating preprocess images and saving them"""

def preprocess_imgs(set_name, img_size):
    """
    Resize and apply VGG-15 preprocessing
    """
    set_new = []
    for img in set_name:
        img = cv2.resize(
            img,
            dsize=img_size,
            interpolation=cv2.INTER_CUBIC
        )
        set_new.append(preprocess_input(img))
    return np.array(set_new)

X_train_prep = preprocess_imgs(set_name=X_train_crop, img_size=IMG_SIZE)
X_test_prep = preprocess_imgs(set_name=X_test_crop, img_size=IMG_SIZE)
X_val_prep = preprocess_imgs(set_name=X_val_crop, img_size=IMG_SIZE)

TRAIN_DIR = '/content/TRAIN_CROP/'
VAL_DIR = '/content/VAL_CROP/'

train_datagen = ImageDataGenerator(
    rotation_range=15,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    brightness_range=[0.5, 1.5],
    horizontal_flip=True,
    vertical_flip=True,
    preprocessing_function=preprocess_input
)

test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)


train_generator = train_datagen.flow_from_directory(
    TRAIN_DIR,
    color_mode='rgb',
    target_size=IMG_SIZE,
    batch_size=1,
    class_mode='binary',
    seed=RANDOM_SEED
)


validation_generator = test_datagen.flow_from_directory(
    VAL_DIR,
    color_mode='rgb',
    target_size=IMG_SIZE,
    batch_size=1,
    class_mode='binary',
    seed=RANDOM_SEED
)

# load base model
vgg = VGG16(
    weights='imagenet',
    include_top=False, 
    input_shape=IMG_SIZE + (3,)
)

NUM_CLASSES= 1
vgg16 = Sequential()
#adding vgg template
vgg16.add(vgg)
#deactivating some neuron
vgg16.add(layers.Dropout(0.3))
vgg16.add(layers.Flatten())
vgg16.add(layers.Dropout(0.5))
vgg16.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))
#removing last layer
vgg16.layers[0].trainable = False

vgg16.compile(
    loss='binary_crossentropy',
    optimizer=RMSprop(lr=1e-4),
    metrics=['accuracy']
)
vgg16.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(lr=0.0003, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False), metrics=["accuracy"])

vgg16.summary()

"""Model fitting"""

import time

start = time.time()

vgg16_model = vgg16.fit(
    train_generator,
    steps_per_epoch=50,
    epochs=120,
    validation_data=validation_generator,
    validation_steps=30,
)


end = time.time()
print(end - start)

# validate on val set
predictions = vgg16.predict(X_test_prep)
predictions = [1 if x>0.5 else 0 for x in predictions]

_, train_acc = vgg16.evaluate(X_val_prep, y_val, verbose=0)
_, test_acc = vgg16.evaluate(X_test_prep, y_test, verbose=0)
print(test_acc)

import matplotlib.pyplot as pyplot

pyplot.figure(figsize=(12,12))
# plot loss during training
pyplot.subplot(211)
pyplot.title('Vgg16 Loss')
pyplot.plot(vgg16_model.history['loss'], label='train_data')
pyplot.plot(vgg16_model.history['val_loss'], label='Validation_data')
pyplot.legend()
# plot accuracy during training
pyplot.subplot(212)
pyplot.title('Vgg16 Accuracy')
pyplot.plot(vgg16_model.history['accuracy'], label='train_data')
pyplot.plot(vgg16_model.history['val_accuracy'], label='Validation_data')
pyplot.legend()
pyplot.show()

print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))

"""Statistics"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import cohen_kappa_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

# accuracy: (tp + tn) / (p + n)
accuracy = accuracy_score(y_test, predictions)
print('Accuracy: %f' % accuracy)
# precision tp / (tp + fp)
precision = precision_score(y_test, predictions)
print('Precision: %f' % precision)
# recall: tp / (tp + fn)
recall = recall_score(y_test, predictions)
print('Recall: %f' % recall)
# f1: 2 tp / (2 tp + fp + fn)
f1 = f1_score(y_test, predictions)
print('F1 score: %f' % f1)

kappa = cohen_kappa_score(y_test, predictions)
print('Cohens kappa: %f' % kappa)
# ROC AUC
auc = roc_auc_score(y_test, predictions)
print('ROC AUC: %f' % auc)
# confusion matrix
matrix = confusion_matrix(y_test, predictions)
print(matrix)